{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7662914c-2804-4717-8370-1dab8557089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "from deepctr_torch.inputs import SparseFeat, DenseFeat, get_feature_names\n",
    "from deepctr_torch.models import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474be655-d875-47b7-9672-ca2d799ed71e",
   "metadata": {},
   "source": [
    "## 1.DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c2605c-1c0a-4959-99ba-5b3532e3a9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 160 samples, validate on 0 samples, 5 steps per epoch\n",
      "Epoch 1/5\n",
      "0s - loss:  0.6188 - binary_crossentropy:  0.6188 - auc:  0.4793\n",
      "Epoch 2/5\n",
      "0s - loss:  0.4964 - binary_crossentropy:  0.4964 - auc:  0.9613\n",
      "Epoch 3/5\n",
      "0s - loss:  0.3512 - binary_crossentropy:  0.3512 - auc:  0.9938\n",
      "Epoch 4/5\n",
      "0s - loss:  0.1906 - binary_crossentropy:  0.1906 - auc:  0.9936\n",
      "Epoch 5/5\n",
      "0s - loss:  0.1104 - binary_crossentropy:  0.1103 - auc:  0.9980\n",
      "\n",
      "test LogLoss 0.5474\n",
      "test AUC 0.5195\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv('./criteo_sample.txt')\n",
    "\n",
    "    sparse_features = ['C' + str(i) for i in range(1, 27)]\n",
    "    dense_features = ['I' + str(i) for i in range(1, 14)]\n",
    "\n",
    "    data[sparse_features] = data[sparse_features].fillna('-1', )\n",
    "    data[dense_features] = data[dense_features].fillna(0, )\n",
    "    target = ['label']\n",
    "\n",
    "    # 1.Label Encoding for sparse features,and do simple Transformation for dense features\n",
    "    for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feat] = lbe.fit_transform(data[feat])\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "    # 2.count #unique features for each sparse field,and record dense feature field name\n",
    "\n",
    "    fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique())\n",
    "                              for feat in sparse_features] + [DenseFeat(feat, 1, )\n",
    "                                                              for feat in dense_features]\n",
    "\n",
    "    dnn_feature_columns = fixlen_feature_columns\n",
    "    linear_feature_columns = fixlen_feature_columns\n",
    "\n",
    "    feature_names = get_feature_names(\n",
    "        linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "    # 3.generate input data for model\n",
    "\n",
    "    train, test = train_test_split(data, test_size=0.2)\n",
    "\n",
    "    train_model_input = {name: train[name] for name in feature_names}\n",
    "    test_model_input = {name: test[name] for name in feature_names}\n",
    "\n",
    "    # 4.Define Model,train,predict and evaluate\n",
    "\n",
    "    device = 'cpu'\n",
    "    use_cuda = False\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        print('cuda ready...')\n",
    "        device = 'cuda:0'\n",
    "\n",
    "    model = DeepFM(linear_feature_columns=linear_feature_columns, dnn_feature_columns=dnn_feature_columns,\n",
    "                   task='binary',\n",
    "                   l2_reg_embedding=1e-5, device=device)\n",
    "\n",
    "    model.compile(\"adagrad\", \"binary_crossentropy\",\n",
    "                  metrics=[\"binary_crossentropy\", \"auc\"], )\n",
    "    model.fit(train_model_input,train[target].values,batch_size=32,epochs=5,verbose=2,validation_split=0.0)\n",
    "\n",
    "    pred_ans = model.predict(test_model_input, 256)\n",
    "    print(\"\")\n",
    "    print(\"test LogLoss\", round(log_loss(test[target].values, pred_ans), 4))\n",
    "    print(\"test AUC\", round(roc_auc_score(test[target].values, pred_ans), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c286b7-8b41-4584-9577-68b1a067c60e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85437f49-6d5a-400b-828f-c2172134bcaa",
   "metadata": {},
   "source": [
    "## 2.DIN&DIEN\n",
    "\n",
    "- See:https://github.com/shenweichen/DeepCTR/blob/master/examples/run_din.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9576cb7-5f9e-49e3-b792-dbb89a0eee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from deepctr_torch.inputs import (DenseFeat, SparseFeat, VarLenSparseFeat,get_feature_names)\n",
    "from deepctr_torch.models import DIN, DIEN, DeepFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aafed94-3ffc-4ae6-baf4-e9d701f35674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4832, 14)\n",
      "(1208, 14)\n",
      "(6040, 14)\n",
      "(6038, 14)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"./train.csv\")\n",
    "print(train.shape)\n",
    "test = pd.read_csv(\"./test.csv\")\n",
    "print(test.shape)\n",
    "\n",
    "data = pd.concat([train,test])\n",
    "print(data.shape)\n",
    "data = data.dropna()\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06056dcd-14f1-41ba-bca4-76d487f62828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>ratting</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>last</th>\n",
       "      <th>histHighRatedMovieIds</th>\n",
       "      <th>negHistMovieIds</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zipCode</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>5</td>\n",
       "      <td>978824351</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1545|527|595|588|1|2355|2294|783|1566|1907</td>\n",
       "      <td>393|2562|3289|3442|2808|2259|295|1190|3321|3470</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "      <td>Pocahontas (1995)</td>\n",
       "      <td>Animation|Children's|Musical|Romance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "      <td>977809337</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3928|1934|2099|3345|1013|1101|3524|3429|3751|2138</td>\n",
       "      <td>3142|1743|525|1746|3323|935|2183|3556|3343|1542</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>77345</td>\n",
       "      <td>Pocahontas (1995)</td>\n",
       "      <td>Animation|Children's|Musical|Romance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4877</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>962767153</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2078|1032|2081|616|364|2033|3034|2394|3745|3615</td>\n",
       "      <td>2354|747|3478|2638|311|1204|3370|807|29|1380</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>94703</td>\n",
       "      <td>Pocahontas (1995)</td>\n",
       "      <td>Animation|Children's|Musical|Romance</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1917</td>\n",
       "      <td>3</td>\n",
       "      <td>978300174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3418|349|1527|2353|1370|648|368|736|2002|1544</td>\n",
       "      <td>2117|2560|3480|3678|2798|1222|3872|3503|3913|3494</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "      <td>Armageddon (1998)</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5122</td>\n",
       "      <td>1917</td>\n",
       "      <td>5</td>\n",
       "      <td>962213528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3078|2858|2907|1584|2571|32|788|1573|2428|1580</td>\n",
       "      <td>1860|194|742|2379|1966|3397|3195|678|2240|2196</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>20009</td>\n",
       "      <td>Armageddon (1998)</td>\n",
       "      <td>Action|Adventure|Sci-Fi|Thriller</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  ratting  timestamp  last  \\\n",
       "0       1       48        5  978824351   1.0   \n",
       "1    2030       48        3  977809337   1.0   \n",
       "2    4877       48        2  962767153   1.0   \n",
       "3       2     1917        3  978300174   1.0   \n",
       "4    5122     1917        5  962213528   1.0   \n",
       "\n",
       "                               histHighRatedMovieIds  \\\n",
       "0         1545|527|595|588|1|2355|2294|783|1566|1907   \n",
       "1  3928|1934|2099|3345|1013|1101|3524|3429|3751|2138   \n",
       "2    2078|1032|2081|616|364|2033|3034|2394|3745|3615   \n",
       "3      3418|349|1527|2353|1370|648|368|736|2002|1544   \n",
       "4     3078|2858|2907|1584|2571|32|788|1573|2428|1580   \n",
       "\n",
       "                                     negHistMovieIds gender  age  occupation  \\\n",
       "0    393|2562|3289|3442|2808|2259|295|1190|3321|3470      F    1          10   \n",
       "1    3142|1743|525|1746|3323|935|2183|3556|3343|1542      M   25           4   \n",
       "2       2354|747|3478|2638|311|1204|3370|807|29|1380      M   25           4   \n",
       "3  2117|2560|3480|3678|2798|1222|3872|3503|3913|3494      M   56          16   \n",
       "4     1860|194|742|2379|1966|3397|3195|678|2240|2196      M   25           0   \n",
       "\n",
       "  zipCode              title                                genres  label  \n",
       "0   48067  Pocahontas (1995)  Animation|Children's|Musical|Romance      1  \n",
       "1   77345  Pocahontas (1995)  Animation|Children's|Musical|Romance      0  \n",
       "2   94703  Pocahontas (1995)  Animation|Children's|Musical|Romance      0  \n",
       "3   70072  Armageddon (1998)      Action|Adventure|Sci-Fi|Thriller      0  \n",
       "4   20009  Armageddon (1998)      Action|Adventure|Sci-Fi|Thriller      1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87450ea6-9377-4dc6-add9-776aba67d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please check the latest version manually on https://pypi.org/project/deepctr-torch/#history\n"
     ]
    }
   ],
   "source": [
    "sparse_features = [\"userId\", \"movieId\",\"gender\", \"age\", \"occupation\", \"zipCode\"]\n",
    "dense_features = ['ratting']\n",
    "sequence_features = ['histHighRatedMovieIds', 'negHistMovieIds']\n",
    "behavior_feature_list = ['movieId']\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a5162ea-8729-4028-b309-4f60f787e994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movieId']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behavior_feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "933f75e3-f2aa-4562-b826-f0cf6d175ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(x, key2index):\n",
    "    key_ans = x.split('|')\n",
    "    for key in key_ans:\n",
    "        if key not in key2index:\n",
    "            # Notice : input value 0 is a special \"padding\",so we do not use 0 to encode valid feature for sequence input\n",
    "            key2index[key] = len(key2index) + 1\n",
    "    return list(map(lambda x: key2index[x], key_ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "685aeabd-607b-4ac5-8734-fe1394d20d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "    \n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "# preprocess the sequence feature\n",
    "# Notice : padding=`post`\n",
    "genres_key2index = {}\n",
    "genres_list = list(map(lambda x: split(x, genres_key2index), data['genres'].values))\n",
    "genres_length = np.array(list(map(len, genres_list)))\n",
    "genres_max_len = max(genres_length)\n",
    "genres_list = pad_sequences(genres_list, maxlen=genres_max_len, padding='post', )\n",
    "\n",
    "highrate_key2index = {}\n",
    "highrate_list = list(map(lambda x: split(x, highrate_key2index), data['histHighRatedMovieIds'].values))\n",
    "highrate_length = np.array(list(map(len, highrate_list)))\n",
    "highrate_max_len = max(highrate_length)\n",
    "highrate_list = pad_sequences(highrate_list, maxlen=highrate_max_len, padding='post', )\n",
    "\n",
    "neghist_key2index = {}\n",
    "neghist_list = list(map(lambda x: split(x, neghist_key2index), data['negHistMovieIds'].values))\n",
    "neghist_length = np.array(list(map(len, neghist_list)))\n",
    "neghist_max_len = max(neghist_length)\n",
    "neghist_list = pad_sequences(neghist_list, maxlen=neghist_max_len, padding='post', ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5f3ce86-6aaf-450b-a1e5-4b047e519811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.count #unique features for each sparse field and generate feature config for sequence feature\n",
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique(), embedding_dim=4) for feat in sparse_features] + \\\n",
    "                            [DenseFeat(feat, 1, ) for feat in dense_features]\n",
    "\n",
    "varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres', vocabulary_size=len(\n",
    "    genres_key2index) + 1, embedding_dim=4), maxlen=genres_max_len, combiner='mean', length_name=\"seq_length\")]  + \\\n",
    "    [VarLenSparseFeat(SparseFeat('hist_movieId', vocabulary_size=len(\n",
    "    highrate_key2index) + 1, embedding_dim=4), maxlen=highrate_max_len, combiner='mean', length_name=\"seq_length\")] + \\\n",
    "    [VarLenSparseFeat(SparseFeat('neg_hist_movieId', vocabulary_size=len(\n",
    "    neghist_key2index) + 1, embedding_dim=4), maxlen=neghist_max_len, combiner='mean', length_name=\"seq_length\")]\n",
    "\n",
    "\n",
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b0acecc6-12de-43d3-99a4-983f40c36418",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['userId',\n",
       " 'movieId',\n",
       " 'gender',\n",
       " 'age',\n",
       " 'occupation',\n",
       " 'zipCode',\n",
       " 'ratting',\n",
       " 'genres',\n",
       " 'seq_length',\n",
       " 'hist_movieId',\n",
       " 'neg_hist_movieId']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6076b2b-986b-445e-af1c-b4aea7a79567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.generate input data for model\n",
    "split_boundary = int(data.shape[0] * 0.8)\n",
    "train, test = data[:split_boundary], data[split_boundary:]\n",
    "\n",
    "train_model_input = {name: train[name] for name in sparse_features+dense_features}\n",
    "train_model_input[\"genres\"] = genres_list[:split_boundary]\n",
    "train_model_input[\"hist_movieId\"] = highrate_list[:split_boundary]\n",
    "train_model_input[\"neg_hist_movieId\"] = neghist_list[:split_boundary]\n",
    "train_model_input[\"seq_length\"] = np.array([10 for i in range(split_boundary)])\n",
    "\n",
    "test_model_input = {name: test[name] for name in sparse_features+dense_features}\n",
    "test_model_input[\"genres\"] = genres_list[split_boundary:]\n",
    "test_model_input[\"hist_movieId\"] = highrate_list[split_boundary:]\n",
    "test_model_input[\"neg_hist_movieId\"] = neghist_list[split_boundary:]\n",
    "test_model_input[\"seq_length\"] = np.array([10 for i in range(genres_list.shape[0]-split_boundary)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d57a3e38-f62b-4fa5-b735-fc8667a03799",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userId': 0          8\n",
       " 1         14\n",
       " 2       2164\n",
       " 3       2318\n",
       " 4         15\n",
       "         ... \n",
       " 1203    5960\n",
       " 1204    5965\n",
       " 1205    5975\n",
       " 1206    6003\n",
       " 1207    6005\n",
       " Name: userId, Length: 1208, dtype: int64,\n",
       " 'movieId': 0       1048\n",
       " 1       1622\n",
       " 2       1622\n",
       " 3       1622\n",
       " 4       1254\n",
       "         ... \n",
       " 1203     679\n",
       " 1204     607\n",
       " 1205     108\n",
       " 1206    1600\n",
       " 1207     903\n",
       " Name: movieId, Length: 1208, dtype: int64,\n",
       " 'gender': 0       1\n",
       " 1       1\n",
       " 2       1\n",
       " 3       1\n",
       " 4       0\n",
       "        ..\n",
       " 1203    1\n",
       " 1204    1\n",
       " 1205    1\n",
       " 1206    0\n",
       " 1207    1\n",
       " Name: gender, Length: 1208, dtype: int64,\n",
       " 'age': 0       2\n",
       " 1       2\n",
       " 2       2\n",
       " 3       3\n",
       " 4       3\n",
       "        ..\n",
       " 1203    2\n",
       " 1204    6\n",
       " 1205    3\n",
       " 1206    0\n",
       " 1207    1\n",
       " Name: age, Length: 1208, dtype: int64,\n",
       " 'occupation': 0       17\n",
       " 1        7\n",
       " 2        7\n",
       " 3        7\n",
       " 4        0\n",
       "         ..\n",
       " 1203    15\n",
       " 1204     7\n",
       " 1205     1\n",
       " 1206     0\n",
       " 1207     4\n",
       " Name: occupation, Length: 1208, dtype: int64,\n",
       " 'zipCode': 0       2106\n",
       " 1        904\n",
       " 2       1171\n",
       " 3       1600\n",
       " 4        801\n",
       "         ... \n",
       " 1203     105\n",
       " 1204    3352\n",
       " 1205    1684\n",
       " 1206      10\n",
       " 1207    2484\n",
       " Name: zipCode, Length: 1208, dtype: int64,\n",
       " 'ratting': 0       0.75\n",
       " 1       1.00\n",
       " 2       1.00\n",
       " 3       0.75\n",
       " 4       0.25\n",
       "         ... \n",
       " 1203    1.00\n",
       " 1204    0.75\n",
       " 1205    0.25\n",
       " 1206    0.50\n",
       " 1207    0.75\n",
       " Name: ratting, Length: 1208, dtype: float64,\n",
       " 'genres': array([[ 1,  2,  0,  0,  0,  0],\n",
       "        [10,  8,  0,  0,  0,  0],\n",
       "        [10,  8,  0,  0,  0,  0],\n",
       "        ...,\n",
       "        [ 9,  0,  0,  0,  0,  0],\n",
       "        [ 9,  0,  0,  0,  0,  0],\n",
       "        [ 5,  9, 12, 10,  0,  0]], dtype=int32),\n",
       " 'hist_movieId': array([[ 259,  108, 1029, ...,  557,  826, 1285],\n",
       "        [1681,   36, 1069, ...,  260, 1162,  673],\n",
       "        [1176,  306,  282, ...,   59,   64,  928],\n",
       "        ...,\n",
       "        [ 605, 2309,  394, ...,   80,  333,    7],\n",
       "        [ 975, 1505,    3, ..., 1841,  811,  247],\n",
       "        [ 276,  419,  825, ...,  146,  408,  800]], dtype=int32),\n",
       " 'neg_hist_movieId': array([[3719, 2362, 1913, ..., 1274, 2711,  670],\n",
       "        [ 284,  750, 1621, ..., 3859, 2614, 3252],\n",
       "        [2121, 2618, 2279, ..., 1494,  695, 3235],\n",
       "        ...,\n",
       "        [2274, 2483,  736, ..., 1699, 2195, 2512],\n",
       "        [ 985, 1139, 1997, ..., 2696, 2756, 1145],\n",
       "        [1104, 1372, 3690, ..., 1421, 2688, 3642]], dtype=int32),\n",
       " 'seq_length': array([10, 10, 10, ..., 10, 10, 10])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20c29b43-65c7-4eee-b2ca-419b8435b04f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 4830 samples, validate on 0 samples, 19 steps per epoch\n",
      "Epoch 1/5\n",
      "1s - loss:  0.6300 - binary_crossentropy:  0.6296 - auc:  0.9186\n",
      "Epoch 2/5\n",
      "1s - loss:  0.3885 - binary_crossentropy:  0.3877 - auc:  0.9937\n",
      "Epoch 3/5\n",
      "1s - loss:  0.1279 - binary_crossentropy:  0.1275 - auc:  0.9998\n",
      "Epoch 4/5\n",
      "1s - loss:  0.0335 - binary_crossentropy:  0.0334 - auc:  1.0000\n",
      "Epoch 5/5\n",
      "1s - loss:  0.0136 - binary_crossentropy:  0.0136 - auc:  1.0000\n"
     ]
    }
   ],
   "source": [
    "# 4.Define Model,compile and train\n",
    "\n",
    "device = 'cpu'\n",
    "use_cuda = False\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary', device=device)\n",
    "\n",
    "model.compile(\"adagrad\", \"binary_crossentropy\",\n",
    "                  metrics=[\"binary_crossentropy\", \"auc\"], )\n",
    "history = model.fit(train_model_input,train[target].values,batch_size=256,epochs=5,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "198a0b04-0b12-4bf1-aa5e-2211314e2817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "label test LogLoss 0.2455\n",
      "label test AUC 0.9657\n"
     ]
    }
   ],
   "source": [
    "pred_ans = model.predict(test_model_input, 256)\n",
    "print(\"\")\n",
    "for i, target_name in enumerate(target):\n",
    "    print(\"%s test LogLoss\" % target_name, round(log_loss(test[target[i]].values, pred_ans[:, i]), 4))\n",
    "    print(\"%s test AUC\" % target_name, round(roc_auc_score(test[target[i]].values, pred_ans[:, i]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc2d799-1088-4e28-9f8c-cc6f7ffb3e0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "01f42222-2898-4a86-9938-fe20e4b1ee87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 4830 samples, validate on 0 samples, 49 steps per epoch\n",
      "Epoch 1/5\n",
      "3s - loss:  0.5720 - binary_crossentropy:  0.5696\n",
      "Epoch 2/5\n",
      "3s - loss:  0.1750 - binary_crossentropy:  0.1731\n",
      "Epoch 3/5\n",
      "3s - loss:  0.0237 - binary_crossentropy:  0.0236\n",
      "Epoch 4/5\n",
      "2s - loss:  0.0077 - binary_crossentropy:  0.0076\n",
      "Epoch 5/5\n",
      "2s - loss:  0.0041 - binary_crossentropy:  0.0041\n"
     ]
    }
   ],
   "source": [
    "model = DIN(linear_feature_columns, behavior_feature_list, device=device, att_weight_normalization=True)\n",
    "model.compile('adagrad', 'binary_crossentropy',\n",
    "              metrics=['binary_crossentropy'])\n",
    "history = model.fit(train_model_input,train[target].values, batch_size=100, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "83298033-a25d-4046-b093-0ec6aa078c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "label test LogLoss 0.1496\n",
      "label test AUC 0.9892\n"
     ]
    }
   ],
   "source": [
    "pred_ans = model.predict(test_model_input, 256)\n",
    "print(\"\")\n",
    "for i, target_name in enumerate(target):\n",
    "    print(\"%s test LogLoss\" % target_name, round(log_loss(test[target[i]].values, pred_ans[:, i]), 4))\n",
    "    print(\"%s test AUC\" % target_name, round(roc_auc_score(test[target[i]].values, pred_ans[:, i]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6ba9fddd-4d56-470b-8f13-474db43aa729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 4830 samples, validate on 0 samples, 49 steps per epoch\n",
      "Epoch 1/5\n",
      "6s - loss:  0.5967 - binary_crossentropy:  0.5877\n",
      "Epoch 2/5\n",
      "6s - loss:  0.3385 - binary_crossentropy:  0.3301\n",
      "Epoch 3/5\n",
      "6s - loss:  0.2717 - binary_crossentropy:  0.2656\n",
      "Epoch 4/5\n",
      "6s - loss:  0.2539 - binary_crossentropy:  0.2482\n",
      "Epoch 5/5\n",
      "6s - loss:  0.2427 - binary_crossentropy:  0.2388\n"
     ]
    }
   ],
   "source": [
    "model = DIEN(linear_feature_columns, behavior_feature_list, use_negsampling=True, device=device, att_weight_normalization=True)\n",
    "model.compile('adagrad', 'binary_crossentropy',\n",
    "              metrics=['binary_crossentropy'])\n",
    "history = model.fit(train_model_input,train[target].values, batch_size=100, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b7d66449-db84-4a9c-aa3e-52194408065f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4827</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4828</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4830</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4831</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4830 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0         1\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         1\n",
       "...     ...\n",
       "4827      0\n",
       "4828      1\n",
       "4829      1\n",
       "4830      0\n",
       "4831      1\n",
       "\n",
       "[4830 rows x 1 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f73c41bf-3341-4bb0-a1af-90e73532b56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "label test LogLoss 0.3481\n",
      "label test AUC 0.9991\n"
     ]
    }
   ],
   "source": [
    "pred_ans = model.predict(test_model_input, 256)\n",
    "print(\"\")\n",
    "for i, target_name in enumerate(target):\n",
    "    print(\"%s test LogLoss\" % target_name, round(log_loss(test[target[i]].values, pred_ans[:, i]), 4))\n",
    "    print(\"%s test AUC\" % target_name, round(roc_auc_score(test[target[i]].values, pred_ans[:, i]), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c38aa-08a9-4b5e-b4b7-ca6a8d5700a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf4fa8-8446-4143-847c-881f7381bc15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf9778ca-444c-4df0-bc8a-fab223854e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./train.csv\")\n",
    "data = data.dropna()\n",
    "\n",
    "sparse_features = [\"userId\", \"movieId\",\n",
    "                   \"gender\", \"age\", \"occupation\", \"zipCode\", ]\n",
    "dense_features = ['ratting']\n",
    "sequence_features = ['histHighRatedMovieIds', 'negHistMovieIds']\n",
    "behavior_feature_list = ['movieId']\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "0f4721ab-adb9-45a0-b7d6-5c894e70d47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "1203    1\n",
       "1204    1\n",
       "1205    0\n",
       "1206    0\n",
       "1207    1\n",
       "Name: label, Length: 6038, dtype: int64"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ce20f120-2950-46e6-92b0-09b4f7f1563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.Label Encoding for sparse features,and process sequence features\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "\n",
    "# preprocess the sequence feature\n",
    "key2index = {}\n",
    "# genres_list = list(map(split, data['genres'].values))\n",
    "genres_list = list(map(lambda x: split(x, key2index), data['genres'].values))\n",
    "genres_length = np.array(list(map(len, genres_list)))\n",
    "max_len = max(genres_length)\n",
    "# Notice : padding=`post`\n",
    "genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', )\n",
    "\n",
    "key2index1 = {}\n",
    "# genres_list1 = list(map(split, data['histHighRatedMovieIds'].values))\n",
    "genres_list1 = list(map(lambda x: split(x, key2index1), data['histHighRatedMovieIds'].values))\n",
    "genres_length1 = np.array(list(map(len, genres_list1)))\n",
    "max_len1 = max(genres_length1)\n",
    "# Notice : padding=`post`\n",
    "genres_list1 = pad_sequences(genres_list1, maxlen=max_len1, padding='post', )\n",
    "\n",
    "key2index2 = {}\n",
    "# genres_list2 = list(map(split, data['negHistMovieIds'].values))\n",
    "genres_list2 = list(map(lambda x: split(x, key2index2), data['negHistMovieIds'].values))\n",
    "genres_length2 = np.array(list(map(len, genres_list2)))\n",
    "max_len2 = max(genres_length2)\n",
    "# Notice : padding=`post`\n",
    "genres_list2 = pad_sequences(genres_list2, maxlen=max_len2, padding='post', ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "218f41fa-f37b-4caa-a0e4-84077c853195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# key2index2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0806f3ee-16ad-432d-819e-39c9518ef7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.count #unique features for each sparse field and generate feature config for sequence feature\n",
    "\n",
    "fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique(), embedding_dim=4)\n",
    "                          for feat in sparse_features] + [DenseFeat(feat, 1, ) for feat in dense_features]\n",
    "\n",
    "varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres', vocabulary_size=len(\n",
    "    key2index) + 1, embedding_dim=4), maxlen=max_len, combiner='mean', length_name=\"seq_length\")]  + \\\n",
    "    [VarLenSparseFeat(SparseFeat('hist_movieId', vocabulary_size=len(\n",
    "    key2index1) + 1, embedding_dim=4), maxlen=max_len1, combiner='mean', length_name=\"seq_length\")] + \\\n",
    "    [VarLenSparseFeat(SparseFeat('neg_movieId', vocabulary_size=len(\n",
    "    key2index2) + 1, embedding_dim=4), maxlen=max_len2, combiner='mean', length_name=\"seq_length\")]\n",
    "\n",
    "# varlen_feature_columns += [VarLenSparseFeat(SparseFeat('genres', vocabulary_size=len(key2index) + 1, embedding_dim=4), maxlen=max_len, combiner='mean'),\n",
    "#                         VarLenSparseFeat(SparseFeat('hist_movieId', vocabulary_size=len(key2index1) + 1, embedding_dim=4), maxlen=max_len1, combiner='mean'),\n",
    "#                         VarLenSparseFeat(SparseFeat('negHistMovieIds', vocabulary_size=len(key2index2) + 1, embedding_dim=4), maxlen=max_len2, combiner='mean')]\n",
    "\n",
    "linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "11de967d-4b59-4484-acff-d39e5fbf6de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_item_id = np.array([[1, 2, 3, 0], [1, 2, 3, 0], [1, 2, 0, 0], [1, 2, 0, 0]])\n",
    "hist_item_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "eea4f372-a2a4-4d8f-bdbc-f66390437656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SparseFeat(name='userId', vocabulary_size=4830, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='userId', group_name='default_group'),\n",
       " SparseFeat(name='movieId', vocabulary_size=1715, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='movieId', group_name='default_group'),\n",
       " SparseFeat(name='gender', vocabulary_size=2, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='gender', group_name='default_group'),\n",
       " SparseFeat(name='age', vocabulary_size=7, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='age', group_name='default_group'),\n",
       " SparseFeat(name='occupation', vocabulary_size=21, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='occupation', group_name='default_group'),\n",
       " SparseFeat(name='zipCode', vocabulary_size=2954, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='zipCode', group_name='default_group'),\n",
       " DenseFeat(name='ratting', dimension=1, dtype='float32'),\n",
       " VarLenSparseFeat(sparsefeat=SparseFeat(name='genres', vocabulary_size=19, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='genres', group_name='default_group'), maxlen=6, combiner='mean', length_name='seq_length'),\n",
       " VarLenSparseFeat(sparsefeat=SparseFeat(name='hist_movieId', vocabulary_size=2915, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='hist_movieId', group_name='default_group'), maxlen=10, combiner='mean', length_name='seq_length'),\n",
       " VarLenSparseFeat(sparsefeat=SparseFeat(name='negHistMovieIds', vocabulary_size=3884, embedding_dim=4, use_hash=False, dtype='int32', embedding_name='negHistMovieIds', group_name='default_group'), maxlen=10, combiner='mean', length_name='seq_length')]"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "f0abc362-33ba-4e09-9a87-b8c52e726ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.generate input data for model\n",
    "model_input = {name: data[name].values for name in sparse_features+dense_features}  #\n",
    "model_input[\"genres\"] = genres_list\n",
    "model_input[\"hist_movieId\"] = genres_list1\n",
    "model_input[\"negHistMovieIds\"] = genres_list2\n",
    "model_input[\"seq_length\"] = np.array([10 for i in range(4830)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "5721d10d-40d8-43ec-ac4e-c3a082e80457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4830"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = np.array([10 for i in range(4830)])\n",
    "len(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "3517cffc-e110-4cf1-acea-1d75a957502d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'userId': array([   0, 1590, 3882, ..., 4825, 4827, 4828]),\n",
       " 'movieId': array([ 30,  30,  30, ..., 878, 205, 532]),\n",
       " 'gender': array([0, 1, 1, ..., 1, 0, 0]),\n",
       " 'age': array([0, 2, 2, ..., 4, 4, 4]),\n",
       " 'occupation': array([10,  4,  4, ...,  7,  1,  0]),\n",
       " 'zipCode': array([1349, 2078, 2685, ..., 1581, 2029,   11]),\n",
       " 'ratting': array([1.  , 0.5 , 0.25, ..., 0.75, 0.5 , 0.75]),\n",
       " 'genres': array([[ 1,  2,  3,  4,  0,  0],\n",
       "        [ 1,  2,  3,  4,  0,  0],\n",
       "        [ 1,  2,  3,  4,  0,  0],\n",
       "        ...,\n",
       "        [ 1,  2, 17,  3,  0,  0],\n",
       "        [ 9,  7,  0,  0,  0,  0],\n",
       "        [ 6,  0,  0,  0,  0,  0]], dtype=int32),\n",
       " 'hist_movieId': array([[   1,    2,    3, ...,    8,    9,   10],\n",
       "        [  11,   12,   13, ...,   18,   19,   20],\n",
       "        [  21,   22,   23, ...,   28,   29,   30],\n",
       "        ...,\n",
       "        [  63,  370, 1205, ...,  333, 1232, 1440],\n",
       "        [ 474,  584, 1756, ...,  672,  397,  851],\n",
       "        [ 619, 1040,  229, ...,  385,  334,  203]], dtype=int32),\n",
       " 'negHistMovieIds': array([[   1,    2,    3, ...,    8,    9,   10],\n",
       "        [  11,   12,   13, ...,   18,   19,   20],\n",
       "        [  21,   22,   23, ...,   28,   29,   30],\n",
       "        ...,\n",
       "        [1110, 2572, 1880, ..., 2634,  497, 1767],\n",
       "        [2954, 2581,  477, ..., 3283,  540, 1003],\n",
       "        [2978, 2854,  656, ..., 3832,  304,  284]], dtype=int32),\n",
       " 'seq_length': array([10, 10, 10, ..., 10, 10, 10])}"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sparse_features\n",
    "model_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9405c4eb-2c6b-4b52-90de-487b0232a296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4830, 10)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_input['negHistMovieIds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "4aa7995e-7c69-422d-a977-205fb92988e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 4830 samples, validate on 0 samples, 19 steps per epoch\n",
      "Epoch 1/2\n",
      "1s - loss:  0.6319 - binary_crossentropy:  0.6313 - auc:  0.9035\n",
      "Epoch 2/2\n",
      "1s - loss:  0.3779 - binary_crossentropy:  0.3772 - auc:  0.9956\n"
     ]
    }
   ],
   "source": [
    "# 4.Define Model,compile and train\n",
    "\n",
    "device = 'cpu'\n",
    "use_cuda = False\n",
    "if use_cuda and torch.cuda.is_available():\n",
    "    print('cuda ready...')\n",
    "    device = 'cuda:0'\n",
    "\n",
    "model = DeepFM(linear_feature_columns, dnn_feature_columns, task='binary', device=device)\n",
    "\n",
    "model.compile(\"adagrad\", \"binary_crossentropy\",\n",
    "                  metrics=[\"binary_crossentropy\", \"auc\"], )\n",
    "history = model.fit(model_input,data[target].values,batch_size=256,epochs=2,verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b4f71207-00e9-436c-8bed-11b13984a7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6038 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label\n",
       "0         1\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         1\n",
       "...     ...\n",
       "1203      1\n",
       "1204      1\n",
       "1205      0\n",
       "1206      0\n",
       "1207      1\n",
       "\n",
       "[6038 rows x 1 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "fe9bfdd3-9722-4b4b-9323-9d51100f68ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['movieId']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# linear_feature_columns\n",
    "behavior_feature_list\n",
    "# model_input['negHistMovieIds'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "ae07af6f-4c17-43d1-9a0c-be1ce2458e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "Train on 4830 samples, validate on 0 samples, 49 steps per epoch\n",
      "Epoch 1/5\n",
      "3s - loss:  0.4957 - binary_crossentropy:  0.4922\n",
      "Epoch 2/5\n",
      "3s - loss:  0.0865 - binary_crossentropy:  0.0856\n",
      "Epoch 3/5\n",
      "3s - loss:  0.0116 - binary_crossentropy:  0.0116\n",
      "Epoch 4/5\n",
      "3s - loss:  0.0047 - binary_crossentropy:  0.0047\n",
      "Epoch 5/5\n",
      "3s - loss:  0.0027 - binary_crossentropy:  0.0027\n"
     ]
    }
   ],
   "source": [
    "model = DIN(linear_feature_columns, behavior_feature_list, device=device, att_weight_normalization=True)\n",
    "model.compile('adagrad', 'binary_crossentropy',\n",
    "              metrics=['binary_crossentropy'])\n",
    "history = model.fit(model_input, data[target].values, batch_size=100, epochs=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7f496f-8760-4e5c-b6b6-8cf0a4ae2c29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79fc1d71-a440-4919-8c0a-30ad08efbd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    data = pd.read_csv(\"./train.csv\")\n",
    "    sparse_features = [\"userId\", \"movieId\",\n",
    "                       \"gender\", \"age\", \"occupation\", \"zipCode\", ]\n",
    "    dense_features = ['ratting']\n",
    "    sequence_features = ['histHighRatedMovieIds', 'negHistMovieIds']\n",
    "    behavior_feature_list = ['movieId']\n",
    "    target = ['label']\n",
    "\n",
    "    # 1.Label Encoding for sparse features,and process sequence features\n",
    "    for feat in sparse_features:\n",
    "        lbe = LabelEncoder()\n",
    "        data[feat] = lbe.fit_transform(data[feat])\n",
    "    mms = MinMaxScaler(feature_range=(0, 1))\n",
    "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
    "    \n",
    "    # preprocess the sequence feature\n",
    "    key2index = {}\n",
    "    genres_list = list(map(split, data['genres'].values))\n",
    "    genres_length = np.array(list(map(len, genres_list)))\n",
    "    max_len = max(genres_length)\n",
    "    # Notice : padding=`post`\n",
    "    genres_list = pad_sequences(genres_list, maxlen=max_len, padding='post', )\n",
    "    \n",
    "    key2index1 = {}\n",
    "    genres_list1 = list(map(split, data['histHighRatedMovieIds'].values))\n",
    "    genres_length1 = np.array(list(map(len, genres_list1)))\n",
    "    max_len1 = max(genres_length1)\n",
    "    # Notice : padding=`post`\n",
    "    genres_list1 = pad_sequences(genres_list1, maxlen=max_len1, padding='post', )\n",
    "    \n",
    "    key2index2 = {}\n",
    "    genres_list2 = list(map(split, data['negHistMovieIds'].values))\n",
    "    genres_length2 = np.array(list(map(len, genres_list2)))\n",
    "    max_len2 = max(genres_length2)\n",
    "    # Notice : padding=`post`\n",
    "    genres_list2 = pad_sequences(genres_list2, maxlen=max_len2, padding='post', ) \n",
    "    \n",
    "\n",
    "    # 2.count #unique features for each sparse field and generate feature config for sequence feature\n",
    "\n",
    "    fixlen_feature_columns = [SparseFeat(feat, data[feat].nunique(), embedding_dim=4)\n",
    "                              for feat in sparse_features + [DenseFeat(feat, 1, )for feat in dense_features]] \n",
    "\n",
    "    varlen_feature_columns = [VarLenSparseFeat(SparseFeat('genres', vocabulary_size=len(\n",
    "        key2index) + 1, embedding_dim=4), maxlen=max_len, combiner='mean')]  # Notice : value 0 is for padding for sequence input feature\n",
    "\n",
    "    linear_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "    dnn_feature_columns = fixlen_feature_columns + varlen_feature_columns\n",
    "\n",
    "    feature_names = get_feature_names(linear_feature_columns + dnn_feature_columns)\n",
    "\n",
    "    # 3.generate input data for model\n",
    "    model_input = {name: data[name] for name in sparse_features}  #\n",
    "    model_input[\"genres\"] = genres_list\n",
    "\n",
    "    # 4.Define Model,compile and train\n",
    "\n",
    "    device = 'cpu'\n",
    "    use_cuda = True\n",
    "    if use_cuda and torch.cuda.is_available():\n",
    "        print('cuda ready...')\n",
    "        device = 'cuda:0'\n",
    "\n",
    "    model = DeepFM(linear_feature_columns, dnn_feature_columns, task='regression', device=device)\n",
    "\n",
    "    model.compile(\"adam\", \"mse\", metrics=['mse'], )\n",
    "    history = model.fit(model_input,data[target].values,batch_size=256,epochs=10,verbose=2,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4224a9cf-6ad3-4115-9e4f-309bdfed2171",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
