{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73051892-9874-48fe-aed1-2767cc806290",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as Data\n",
    "\n",
    "import time, json, datetime \n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.metrics import log_loss, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca98957-1125-4999-ab31-8cc07761d66c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1382.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>...</td>\n",
       "      <td>e5ba7672</td>\n",
       "      <td>f54016b9</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>b1252a9d</td>\n",
       "      <td>07b5194c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>c5c50484</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>9727dd16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>07c540c4</td>\n",
       "      <td>b04e4670</td>\n",
       "      <td>21ddcdc9</td>\n",
       "      <td>5840adea</td>\n",
       "      <td>60f6221e</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>43f13e8b</td>\n",
       "      <td>e8b83407</td>\n",
       "      <td>731c3655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>767.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>245.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8efede7f</td>\n",
       "      <td>3412118d</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e587c466</td>\n",
       "      <td>ad3062eb</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>3b183c5c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>893</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4392.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>74ef3502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6b3a5ca6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3a171ecb</td>\n",
       "      <td>9117a34a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1e88c74f</td>\n",
       "      <td>26b3c7a7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21c9516a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32c7478e</td>\n",
       "      <td>b34f3128</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label   I1   I2    I3    I4      I5    I6    I7   I8     I9  ...       C17  \\\n",
       "0      0  1.0    1   5.0   0.0  1382.0   4.0  15.0  2.0  181.0  ...  e5ba7672   \n",
       "1      0  2.0    0  44.0   1.0   102.0   8.0   2.0  2.0    4.0  ...  07c540c4   \n",
       "2      0  2.0    0   1.0  14.0   767.0  89.0   4.0  2.0  245.0  ...  8efede7f   \n",
       "3      0  NaN  893   NaN   NaN  4392.0   NaN   0.0  0.0    0.0  ...  1e88c74f   \n",
       "4      0  3.0   -1   NaN   0.0     2.0   0.0   3.0  0.0    0.0  ...  1e88c74f   \n",
       "\n",
       "        C18       C19       C20       C21       C22       C23       C24  \\\n",
       "0  f54016b9  21ddcdc9  b1252a9d  07b5194c       NaN  3a171ecb  c5c50484   \n",
       "1  b04e4670  21ddcdc9  5840adea  60f6221e       NaN  3a171ecb  43f13e8b   \n",
       "2  3412118d       NaN       NaN  e587c466  ad3062eb  3a171ecb  3b183c5c   \n",
       "3  74ef3502       NaN       NaN  6b3a5ca6       NaN  3a171ecb  9117a34a   \n",
       "4  26b3c7a7       NaN       NaN  21c9516a       NaN  32c7478e  b34f3128   \n",
       "\n",
       "        C25       C26  \n",
       "0  e8b83407  9727dd16  \n",
       "1  e8b83407  731c3655  \n",
       "2       NaN       NaN  \n",
       "3       NaN       NaN  \n",
       "4       NaN       NaN  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['label', 'I1', 'I2', 'I3', 'I4', 'I5', 'I6', 'I7', 'I8', 'I9', 'I10', 'I11',\n",
    "       'I12', 'I13', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6', 'C7', 'C8', 'C9',\n",
    "       'C10', 'C11', 'C12', 'C13', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19',\n",
    "       'C20', 'C21', 'C22', 'C23', 'C24', 'C25', 'C26']\n",
    "data = pd.read_csv('./dac_sample.txt',sep='\\t',header=None, names=columns)\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a8320e1-b6de-4c50-bd25-86b447ab0926",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"criteo_sample_50w.csv\")\n",
    "\n",
    "dense_features = [f for f in data.columns.tolist() if f[0] == \"I\"]\n",
    "sparse_features = [f for f in data.columns.tolist() if f[0] == \"C\"]\n",
    "\n",
    "data[sparse_features] = data[sparse_features].fillna('-10086', )\n",
    "data[dense_features] = data[dense_features].fillna(0, )\n",
    "target = ['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a503bdf5-f550-464a-ad7c-34b7400befb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 40)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>I4</th>\n",
       "      <th>I5</th>\n",
       "      <th>I6</th>\n",
       "      <th>I7</th>\n",
       "      <th>I8</th>\n",
       "      <th>I9</th>\n",
       "      <th>...</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>C22</th>\n",
       "      <th>C23</th>\n",
       "      <th>C24</th>\n",
       "      <th>C25</th>\n",
       "      <th>C26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.136628</td>\n",
       "      <td>-0.278599</td>\n",
       "      <td>-0.057666</td>\n",
       "      <td>-0.649408</td>\n",
       "      <td>-0.239004</td>\n",
       "      <td>-0.307323</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>-0.248508</td>\n",
       "      <td>0.219409</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>2422</td>\n",
       "      <td>150</td>\n",
       "      <td>3</td>\n",
       "      <td>1163</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>9570</td>\n",
       "      <td>41</td>\n",
       "      <td>5604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.011844</td>\n",
       "      <td>-0.281089</td>\n",
       "      <td>0.022764</td>\n",
       "      <td>-0.551940</td>\n",
       "      <td>-0.258904</td>\n",
       "      <td>-0.295105</td>\n",
       "      <td>-0.195436</td>\n",
       "      <td>-0.248508</td>\n",
       "      <td>-0.410853</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1727</td>\n",
       "      <td>150</td>\n",
       "      <td>1</td>\n",
       "      <td>14512</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3233</td>\n",
       "      <td>41</td>\n",
       "      <td>4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.011844</td>\n",
       "      <td>-0.281089</td>\n",
       "      <td>-0.065915</td>\n",
       "      <td>0.715132</td>\n",
       "      <td>-0.248565</td>\n",
       "      <td>-0.047694</td>\n",
       "      <td>-0.164176</td>\n",
       "      <td>-0.248508</td>\n",
       "      <td>0.447300</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>510</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34644</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2818</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.261411</td>\n",
       "      <td>1.942945</td>\n",
       "      <td>-0.067977</td>\n",
       "      <td>-0.649408</td>\n",
       "      <td>-0.192208</td>\n",
       "      <td>-0.319541</td>\n",
       "      <td>-0.226697</td>\n",
       "      <td>-0.291501</td>\n",
       "      <td>-0.425097</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15997</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6971</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.112939</td>\n",
       "      <td>-0.283580</td>\n",
       "      <td>-0.067977</td>\n",
       "      <td>-0.649408</td>\n",
       "      <td>-0.260458</td>\n",
       "      <td>-0.319541</td>\n",
       "      <td>-0.179806</td>\n",
       "      <td>-0.291501</td>\n",
       "      <td>-0.425097</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>390</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8663</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label        I1        I2        I3        I4        I5        I6  \\\n",
       "0      0 -0.136628 -0.278599 -0.057666 -0.649408 -0.239004 -0.307323   \n",
       "1      0 -0.011844 -0.281089  0.022764 -0.551940 -0.258904 -0.295105   \n",
       "2      0 -0.011844 -0.281089 -0.065915  0.715132 -0.248565 -0.047694   \n",
       "3      0 -0.261411  1.942945 -0.067977 -0.649408 -0.192208 -0.319541   \n",
       "4      0  0.112939 -0.283580 -0.067977 -0.649408 -0.260458 -0.319541   \n",
       "\n",
       "         I7        I8        I9  ...  C17   C18  C19  C20    C21  C22  C23  \\\n",
       "0  0.007756 -0.248508  0.219409  ...    9  2422  150    3   1163    0    2   \n",
       "1 -0.195436 -0.248508 -0.410853  ...    0  1727  150    1  14512    0    2   \n",
       "2 -0.164176 -0.248508  0.447300  ...    6   510    0    0  34644    6    2   \n",
       "3 -0.226697 -0.291501 -0.425097  ...    1  1170    0    0  15997    0    2   \n",
       "4 -0.179806 -0.291501 -0.425097  ...    1   390    0    0   5101    0    1   \n",
       "\n",
       "    C24  C25   C26  \n",
       "0  9570   41  5604  \n",
       "1  3233   41  4215  \n",
       "2  2818    0     0  \n",
       "3  6971    0     0  \n",
       "4  8663    0     0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 类别特征labelencoder\n",
    "for feat in sparse_features:\n",
    "    lbe = LabelEncoder()\n",
    "    data[feat] = lbe.fit_transform(data[feat])\n",
    "\n",
    "## 数值特征标准化\n",
    "for feat in dense_features:\n",
    "    mean = data[feat].mean()\n",
    "    std = data[feat].std()\n",
    "    data[feat] = (data[feat] - mean) / (std + 1e-12)   # 防止除零\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03a6b095-7276-4cf0-b498-bfe6891d59a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80000, 40) (20000, 40)\n",
      "{'Total': 1269936, 'Trainable': 1269936}\n"
     ]
    }
   ],
   "source": [
    "train, valid = train_test_split(data, test_size=0.2, random_state=2020)\n",
    "print(train.shape, valid.shape)\n",
    "\n",
    "train_dataset = Data.TensorDataset(torch.LongTensor(train[sparse_features].values), \n",
    "                                   torch.FloatTensor(train[dense_features].values),\n",
    "                                   torch.FloatTensor(train['label'].values),)\n",
    "\n",
    "train_loader = Data.DataLoader(dataset=train_dataset, batch_size=2048, shuffle=True)\n",
    "\n",
    "valid_dataset = Data.TensorDataset(torch.LongTensor(valid[sparse_features].values), \n",
    "                                   torch.FloatTensor(valid[dense_features].values),\n",
    "                                   torch.FloatTensor(valid['label'].values),)\n",
    "valid_loader = Data.DataLoader(dataset=valid_dataset, batch_size=4096, shuffle=False)\n",
    "\n",
    "\n",
    "# 打印模型参数\n",
    "def get_parameter_number(model):\n",
    "    total_num = sum(p.numel() for p in model.parameters())\n",
    "    trainable_num = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return {'Total': total_num, 'Trainable': trainable_num}\n",
    "print(get_parameter_number(model))\n",
    "\n",
    "# 定义日志（data文件夹下，同级目录新建一个data文件夹）\n",
    "def write_log(w):\n",
    "    file_name = 'data/' + datetime.date.today().strftime('%m%d')+\"_{}.log\".format(\"deepfm\")\n",
    "    t0 = datetime.datetime.now().strftime('%H:%M:%S')\n",
    "    info = \"{} : {}\".format(t0, w)\n",
    "    print(info)\n",
    "    with open(file_name, 'a') as f: \n",
    "        f.write(info + '\\n') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c3098d7e-cd22-408c-933c-408248077248",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepFM(nn.Module):\n",
    "    def __init__(self, cate_fea_nuniqs, nume_fea_size=0, emb_size=8, \n",
    "                 hid_dims=[256, 128], num_classes=1, dropout=[0.2, 0.2]): \n",
    "        \"\"\"\n",
    "        cate_fea_nuniqs: 类别特征的唯一值个数列表，也就是每个类别特征的vocab_size所组成的列表\n",
    "        nume_fea_size: 数值特征的个数，该模型会考虑到输入全为类别型，即没有数值特征的情况 \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.cate_fea_size = len(cate_fea_nuniqs)\n",
    "        self.nume_fea_size = nume_fea_size\n",
    "        \n",
    "        \"\"\"FM部分\"\"\"\n",
    "        # 一阶\n",
    "        if self.nume_fea_size != 0:\n",
    "            self.fm_1st_order_dense = nn.Linear(self.nume_fea_size, 1)  # 数值特征的一阶表示\n",
    "        self.fm_1st_order_sparse_emb = nn.ModuleList([\n",
    "            nn.Embedding(voc_size, 1) for voc_size in cate_fea_nuniqs])  # 类别特征的一阶表示\n",
    "        \n",
    "        # 二阶\n",
    "        self.fm_2nd_order_sparse_emb = nn.ModuleList([\n",
    "            nn.Embedding(voc_size, emb_size) for voc_size in cate_fea_nuniqs])  # 类别特征的二阶表示\n",
    "        \n",
    "        \"\"\"DNN部分\"\"\"\n",
    "        # self.all_dims = [self.cate_fea_size * emb_size] + hid_dims\n",
    "        self.all_dims = [(self.cate_fea_size * emb_size)+self.nume_fea_size] + hid_dims\n",
    "        self.dense_linear = nn.Linear(self.nume_fea_size, self.cate_fea_size * emb_size)  # 数值特征的维度变换到FM输出维度一致\n",
    "        self.relu = nn.ReLU()\n",
    "        # for DNN \n",
    "        for i in range(1, len(self.all_dims)):\n",
    "            setattr(self, 'linear_'+str(i), nn.Linear(self.all_dims[i-1], self.all_dims[i]))\n",
    "            setattr(self, 'batchNorm_' + str(i), nn.BatchNorm1d(self.all_dims[i]))\n",
    "            setattr(self, 'activation_' + str(i), nn.ReLU())\n",
    "            setattr(self, 'dropout_'+str(i), nn.Dropout(dropout[i-1]))\n",
    "        # for output \n",
    "        self.dnn_linear = nn.Linear(hid_dims[-1], num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, X_sparse, X_dense=None):\n",
    "        \"\"\"\n",
    "        X_sparse: 类别型特征输入  [bs, cate_fea_size]\n",
    "        X_dense: 数值型特征输入（可能没有）  [bs, dense_fea_size]\n",
    "        \"\"\"\n",
    "        \n",
    "        \"\"\"FM 一阶部分\"\"\"\n",
    "        fm_1st_sparse_res = [emb(X_sparse[:, i].unsqueeze(1)).view(-1, 1) \n",
    "                             for i, emb in enumerate(self.fm_1st_order_sparse_emb)]\n",
    "        fm_1st_sparse_res = torch.cat(fm_1st_sparse_res, dim=1)  # [bs, cate_fea_size]\n",
    "        fm_1st_sparse_res = torch.sum(fm_1st_sparse_res, 1,  keepdim=True)  # [bs, 1]\n",
    "        \n",
    "        if X_dense is not None:\n",
    "            fm_1st_dense_res = self.fm_1st_order_dense(X_dense) \n",
    "            fm_1st_part = fm_1st_sparse_res + fm_1st_dense_res\n",
    "        else:\n",
    "            fm_1st_part = fm_1st_sparse_res   # [bs, 1]\n",
    "        \n",
    "        \"\"\"FM 二阶部分\"\"\"\n",
    "        fm_2nd_order_res = [emb(X_sparse[:, i].unsqueeze(1)) for i, emb in enumerate(self.fm_2nd_order_sparse_emb)]\n",
    "        fm_2nd_concat_1d = torch.cat(fm_2nd_order_res, dim=1)  # [bs, n, emb_size]  n为类别型特征个数(cate_fea_size)\n",
    "        \n",
    "        # 先求和再平方\n",
    "        sum_embed = torch.sum(fm_2nd_concat_1d, 1)  # [bs, emb_size]\n",
    "        square_sum_embed = sum_embed * sum_embed    # [bs, emb_size]\n",
    "        # 先平方再求和\n",
    "        square_embed = fm_2nd_concat_1d * fm_2nd_concat_1d  # [bs, n, emb_size]\n",
    "        sum_square_embed = torch.sum(square_embed, 1)  # [bs, emb_size]\n",
    "        # 相减除以2 \n",
    "        sub = square_sum_embed - sum_square_embed  \n",
    "        sub = sub * 0.5   # [bs, emb_size]\n",
    "        \n",
    "        fm_2nd_part = torch.sum(sub, 1, keepdim=True)   # [bs, 1]\n",
    "        \n",
    "        \"\"\"DNN部分\"\"\"\n",
    "        dnn_out = torch.flatten(fm_2nd_concat_1d, 1)   # [bs, n * emb_size]\n",
    "        \n",
    "        if X_dense is not None:\n",
    "            dense_out = self.relu(self.dense_linear(X_dense))   # [bs, n * emb_size]\n",
    "            # dnn_out = dnn_out + dense_out   # [bs, n * emb_size]\n",
    "            dnn_out = torch.cat([dnn_out, X_dense], dim=1) # [bs, n * emb_size + dense_fea_szie]\n",
    "        \n",
    "        for i in range(1, len(self.all_dims)):\n",
    "            dnn_out = getattr(self, 'linear_' + str(i))(dnn_out)\n",
    "            dnn_out = getattr(self, 'batchNorm_' + str(i))(dnn_out)\n",
    "            dnn_out = getattr(self, 'activation_' + str(i))(dnn_out)\n",
    "            dnn_out = getattr(self, 'dropout_' + str(i))(dnn_out)\n",
    "        \n",
    "        dnn_out = self.dnn_linear(dnn_out)   # [bs, 1]\n",
    "        out = fm_1st_part + fm_2nd_part + dnn_out   # [bs, 1]\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3f95a-e19c-4de8-8c55-43009e5bb7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"一些可以调整的地方\n",
    "1.dnn层输入特征\n",
    "    - dnn_out = dnn_out + dense_out   # [bs, n * emb_size]\n",
    "    - dnn_out = torch.cat([dnn_out, X_dense], dim=1) # [bs, n * emb_size + dense_fea_szie]\n",
    "    \n",
    "2.sigmoid层输入\n",
    "    - element-wise: fm_1st_part + fm_2nd_part + dnn_out   # [bs, 1]\n",
    "    - concat: 修改预测函数\n",
    "    def binary_prediction_layer(final_logit: torch.Tensor):\n",
    "        # 将fm+dnn的输出concat后加一层线性层\n",
    "        outputs = nn.Linear(final_logit.size(1), 1)(final_logit)\n",
    "        print(outputs)\n",
    "        outputs = torch.sigmoid(outputs)\n",
    "        return outputs\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5207e291-76e3-4fbe-b7d4-27cc6ca04c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)\n",
    "cate_fea_nuniqs = [data[f].nunique() for f in sparse_features]\n",
    "model = DeepFM(cate_fea_nuniqs, nume_fea_size=len(dense_features))\n",
    "model.to(device)\n",
    "loss_fcn = nn.BCELoss()  # Loss函数\n",
    "loss_fcn = loss_fcn.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005, weight_decay=0.001) \n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3d36d4f8-9dca-4748-831c-be95cd08eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_eval(model, train_loader, valid_loader, epochs, device):\n",
    "    best_auc = 0.0\n",
    "    for _ in range(epochs):\n",
    "        \"\"\"训练部分\"\"\"\n",
    "        model.train()\n",
    "        print(\"Current lr : {}\".format(optimizer.state_dict()['param_groups'][0]['lr']))\n",
    "        write_log('Epoch: {}'.format(_ + 1))\n",
    "        train_loss_sum = 0.0\n",
    "        start_time = time.time()\n",
    "        for idx, x in enumerate(train_loader):\n",
    "            cate_fea, nume_fea, label = x[0], x[1], x[2]\n",
    "            cate_fea, nume_fea, label = cate_fea.to(device), nume_fea.to(device), label.float().to(device)\n",
    "            pred = model(cate_fea, nume_fea).view(-1)\n",
    "            loss = loss_fcn(pred, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss_sum += loss.cpu().item()\n",
    "            if (idx+1) % 50 == 0 or (idx + 1) == len(train_loader):\n",
    "                write_log(\"Epoch {:04d} | Step {:04d} / {} | Loss {:.4f} | Time {:.4f}\".format(\n",
    "                          _+1, idx+1, len(train_loader), train_loss_sum/(idx+1), time.time() - start_time))\n",
    "        scheduler.step()\n",
    "        \"\"\"推断部分\"\"\"\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            valid_labels, valid_preds = [], []\n",
    "            for idx, x in tqdm(enumerate(valid_loader)):\n",
    "                cate_fea, nume_fea, label = x[0], x[1], x[2]\n",
    "                cate_fea, nume_fea = cate_fea.to(device), nume_fea.to(device)\n",
    "                pred = model(cate_fea, nume_fea).reshape(-1).data.cpu().numpy().tolist()\n",
    "                valid_preds.extend(pred)\n",
    "                valid_labels.extend(label.cpu().numpy().tolist())\n",
    "        cur_auc = roc_auc_score(valid_labels, valid_preds)\n",
    "        if cur_auc > best_auc:\n",
    "            best_auc = cur_auc\n",
    "            torch.save(model.state_dict(), \"data/deepfm_best.pth\")\n",
    "        write_log('Current AUC: %.6f, Best AUC: %.6f\\n' % (cur_auc, best_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7131a1f4-310a-4192-880b-6feade174521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current lr : 0.005\n",
      "10:36:09 : Epoch: 1\n",
      "10:36:13 : Epoch 0001 | Step 0040 / 40 | Loss 21.5357 | Time 4.6699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 10.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:36:14 : Current AUC: 0.590020, Best AUC: 0.590020\n",
      "\n",
      "Current lr : 0.004\n",
      "10:36:14 : Epoch: 2\n",
      "10:36:19 : Epoch 0002 | Step 0040 / 40 | Loss 13.4166 | Time 4.6223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:36:19 : Current AUC: 0.648386, Best AUC: 0.648386\n",
      "\n",
      "Current lr : 0.0032\n",
      "10:36:19 : Epoch: 3\n",
      "10:36:24 : Epoch 0003 | Step 0040 / 40 | Loss 11.3209 | Time 4.5787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 23.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:36:24 : Current AUC: 0.667182, Best AUC: 0.667182\n",
      "\n",
      "Current lr : 0.00256\n",
      "10:36:24 : Epoch: 4\n",
      "10:36:29 : Epoch 0004 | Step 0040 / 40 | Loss 9.6106 | Time 5.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 23.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:36:30 : Current AUC: 0.666291, Best AUC: 0.667182\n",
      "\n",
      "Current lr : 0.0020480000000000003\n",
      "10:36:30 : Epoch: 5\n",
      "10:36:35 : Epoch 0005 | Step 0040 / 40 | Loss 7.7804 | Time 4.9468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:00, 23.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10:36:35 : Current AUC: 0.675655, Best AUC: 0.675655\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_and_eval(model, train_loader, valid_loader, 5, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
